{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes for Sentiment Analysis\n",
    "\n",
    "In this project, we'll be working with a CSV file containing movie reviews. Each row contains the text of the review, as well as a number indicating whether the tone of the review is positive(1) or negative(-1).\n",
    "\n",
    "We want to predict whether a review is negative or positive, based on the text alone.\n",
    "\n",
    "All we have is one long string, but we can generate features from it. The easiest way to generate features from text is to split the text up into words. Each word in a movie review will then be a feature that we can work with. To do this, we'll split the reviews based on whitespace.\n",
    "\n",
    "Afterwards, we'll count up how many times each word occurs in the negative reviews, and how many times each word occurs in the positive reviews. Eventually, we'll use the counts to compute the probability that a new review will belong to one class versus the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative text sample: plot : two teen couples go to a church party drink and then drive . they get into an accident . one \n",
      "Positive text sample: films adapted from comic books have had plenty of success whether they're about superheroes ( batman\n"
     ]
    }
   ],
   "source": [
    "# A nice Python class that lets us count how many times items occur in a list\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Read in the training data\n",
    "with open(\"train.csv\", 'r') as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "\n",
    "def get_text(reviews, score):\n",
    "    # Join together the text in the reviews for a particular tone\n",
    "    # Lowercase the text so that the algorithm doesn't see \"Not\" and \"not\" as different words, for example\n",
    "    return \" \".join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "\n",
    "def count_text(text):\n",
    "    # Split text into words based on whitespace -- simple but effective\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    # Count up the occurrence of each word\n",
    "    return Counter(words)\n",
    "\n",
    "negative_text = get_text(reviews, -1)\n",
    "positive_text = get_text(reviews, 1)\n",
    "# Generate word counts for negative tone\n",
    "negative_counts = count_text(negative_text)\n",
    "# Generate word counts for positive tone\n",
    "positive_counts = count_text(positive_text)\n",
    "\n",
    "print(\"Negative text sample: {0}\".format(negative_text[:100]))\n",
    "print(\"Positive text sample: {0}\".format(positive_text[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: plot : two teen couples go to a church party drink and then drive . they get into an accident . one of the guys dies but his girlfriend continues to see him in her life and has nightmares . what's the deal ? watch the movie and \" sorta \" find out . . . critique : a mind-fuck movie for the teen generation that touches on a very cool idea but presents it in a very bad package . which is what makes this review an even harder one to write since i generally applaud films which attempt\n",
      "Negative prediction: 3.005053036235652e-221\n",
      "Positive prediction: 1.307170546690679e-226\n"
     ]
    }
   ],
   "source": [
    "def get_y_count(score):\n",
    "    # Compute the count of each classification occurring in the data\n",
    "    return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "# We'll use these counts for smoothing when computing the prediction\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "\n",
    "# These are the class probabilities (we saw them in the formula as P(y))\n",
    "prob_positive = positive_review_count / len(reviews)\n",
    "prob_negative = negative_review_count / len(reviews)\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    for word in text_counts:\n",
    "        # For every word in the text, we get the number of times that word occurred in the reviews for a given class, add 1 to smooth the value, and divide by the total number of words in the class (plus the class_count, also to smooth the denominator)\n",
    "        # Smoothing ensures that we don't multiply the prediction by 0 if the word didn't exist in the training data\n",
    "        # We also smooth the denominator counts to keep things even\n",
    "        prediction *=  text_counts.get(word) * ((counts.get(word, 0) + 1) / (sum(counts.values()) + class_count))\n",
    "    # Now we multiply by the probability of the class existing in the documents\n",
    "    return prediction * class_prob\n",
    "\n",
    "# Now we can generate probabilities for the classes our reviews belong to\n",
    "# The probabilities themselves aren't very useful -- we make our classification decision based on which value is greater\n",
    "print(\"Review: {0}\".format(reviews[0][0]))\n",
    "print(\"Negative prediction: {0}\".format(make_class_prediction(reviews[0][0], negative_counts, prob_negative, negative_review_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(reviews[0][0], positive_counts, prob_positive, positive_review_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)\n",
    "\n",
    "    # We assign a classification based on which probability is greater\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return -1\n",
    "    return 1\n",
    "\n",
    "with open(\"test.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the predictions: 0.680701754385965\n"
     ]
    }
   ],
   "source": [
    "actual = [int(r[1]) for r in test]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate the ROC curve using scikits-learn\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve\n",
    "# The closer to 1 it is, the \"better\" the predictions\n",
    "print(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of extensions we could add to this algorithm to make it perform better. We could look at n-grams instead of unigrams, for example. We could also remove punctuation and other non-characters. We could remove stopwords, or perform stemming or lemmatization\n",
    "\n",
    "Let's now use the Scikit algorithm for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomal naive bayes AUC: 0.635500515995872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate counts from text using a vectorizer  \n",
    "# We can choose from other available vectorizers, and set many different options\n",
    "# This code performs our step of computing word counts\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=.05)\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a Naive Bayes model to the training data\n",
    "# This will train the model using the word counts we computed and the existing classifications in the training set\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error\n",
    "# It's slightly different from our model because the internals of this process work differently from our implementation\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "print(\"Multinomal naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We can see that our own function performed a little better than the Scikit algorithm. However, they both could perform better with some modifications as mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
